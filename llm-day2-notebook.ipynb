{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b1710c-d5d9-4dcc-954e-2938ad1f32cf",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 2\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec84f4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-ml-python==1.0.12\n",
      "  Downloading snowflake_ml_python-1.0.12-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy<2,>=1.9 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (1.9.1)\n",
      "Requirement already satisfied: snowflake-connector-python[pandas]<4,>=3.0.4 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (3.2.0)\n",
      "Collecting xgboost<2,>=1.7.3\n",
      "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7,>=6.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (6.0)\n",
      "Requirement already satisfied: importlib_resources<6,>=5.1.4 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (5.12.0)\n",
      "Collecting cachetools<5,>=3.1.1\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cloudpickle>=2.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (2.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (1.23.5)\n",
      "Collecting sqlparse<1,>=0.4\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging<24,>=20.9 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (23.1)\n",
      "Requirement already satisfied: fsspec[http]<2024,>=2022.11 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (2023.4.0)\n",
      "Requirement already satisfied: scikit-learn<1.4,>=1.2.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (1.2.2)\n",
      "Requirement already satisfied: s3fs<2024,>=2022.11 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (2023.4.0)\n",
      "Requirement already satisfied: snowflake-snowpark-python<2,>=1.5.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (1.9.0)\n",
      "Collecting absl-py<2,>=0.15\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (3.6.2)\n",
      "Collecting pytimeparse<2,>=1.1.8\n",
      "  Downloading pytimeparse-1.1.8-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pandas<2,>=1.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (1.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-ml-python==1.0.12) (4.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.0.12) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.0.12) (3.4)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.8/site-packages (from fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (3.8.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from importlib_resources<6,>=5.1.4->snowflake-ml-python==1.0.12) (3.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from pandas<2,>=1.0.0->snowflake-ml-python==1.0.12) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from pandas<2,>=1.0.0->snowflake-ml-python==1.0.12) (2023.3)\n",
      "Requirement already satisfied: aiobotocore~=2.5.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12) (2.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from scikit-learn<1.4,>=1.2.1->snowflake-ml-python==1.0.12) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from scikit-learn<1.4,>=1.2.1->snowflake-ml-python==1.0.12) (3.1.0)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (3.15.0)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.2.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2023.7.22)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (3.9.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<3.9.0,>=2.6.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.1.1)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.5.1)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (23.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.26.15)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (1.15.1)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (40.0.1)\n",
      "Requirement already satisfied: tomlkit in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (0.11.1)\n",
      "Requirement already satisfied: pyarrow<10.1.0,>=10.0.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (10.0.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-snowpark-python<2,>=1.5.1->snowflake-ml-python==1.0.12) (0.40.0)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from snowflake-snowpark-python<2,>=1.5.1->snowflake-ml-python==1.0.12) (67.6.1)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiobotocore~=2.5.0->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12) (0.11.0)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiobotocore~=2.5.0->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12) (1.15.0)\n",
      "Requirement already satisfied: botocore<1.29.77,>=1.29.76 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiobotocore~=2.5.0->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12) (1.29.76)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.0.12) (1.3.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/rapids/lib/python3.8/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]<4,>=3.0.4->snowflake-ml-python==1.0.12) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas<2,>=1.0.0->snowflake-ml-python==1.0.12) (1.16.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs<2024,>=2022.11->snowflake-ml-python==1.0.12) (1.0.1)\n",
      "Installing collected packages: pytimeparse, sqlparse, cachetools, absl-py, xgboost, snowflake-ml-python\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.3.0\n",
      "    Uninstalling cachetools-5.3.0:\n",
      "      Successfully uninstalled cachetools-5.3.0\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 1.7.1\n",
      "    Uninstalling xgboost-1.7.1:\n",
      "      Successfully uninstalled xgboost-1.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 cachetools-4.2.4 pytimeparse-1.1.8 snowflake-ml-python-1.0.12 sqlparse-0.4.4 xgboost-1.7.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-ml-python==1.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876bbda5-b330-4d71-a335-ac178274b6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.34.0\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading tokenizers-0.15.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting vllm==0.2.1.post1\n",
      "  Downloading vllm-0.2.1.post1-cp38-cp38-manylinux1_x86_64.whl (28.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.6/28.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py==1.3.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.0/777.0 kB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (23.1)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from transformers==4.34.0) (1.23.5)\n",
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (1.10.7)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastapi in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (0.86.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (5.9.4)\n",
      "Collecting ray>=2.5.1\n",
      "  Downloading ray-2.8.1-cp38-cp38-manylinux2014_x86_64.whl (62.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xformers==0.0.22\n",
      "  Downloading xformers-0.0.22-cp38-cp38-manylinux2014_x86_64.whl (211.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (1.5.3)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (10.0.1)\n",
      "Requirement already satisfied: uvicorn[standard] in /opt/conda/envs/rapids/lib/python3.8/site-packages (from vllm==0.2.1.post1) (0.21.1)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (3.1)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (4.5.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch==2.0.1->vllm==0.2.1.post1) (3.1.2)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m605.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/envs/rapids/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->vllm==0.2.1.post1) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->vllm==0.2.1.post1) (67.6.1)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.27.9-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting accelerate>=0.21.0\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (2023.4.0)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/envs/rapids/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (4.21.12)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (8.1.3)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (4.17.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from ray>=2.5.1->vllm==0.2.1.post1) (1.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->transformers==4.34.0) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->transformers==4.34.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->transformers==4.34.0) (2023.7.22)\n",
      "Requirement already satisfied: starlette==0.20.4 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from fastapi->vllm==0.2.1.post1) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from starlette==0.20.4->fastapi->vllm==0.2.1.post1) (3.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from pandas->vllm==0.2.1.post1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from pandas->vllm==0.2.1.post1) (2023.3)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (0.14.0)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websockets>=10.4 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from uvicorn[standard]->vllm==0.2.1.post1) (10.4)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->vllm==0.2.1.post1) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jinja2->torch==2.0.1->vllm==0.2.1.post1) (2.1.2)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (5.12.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (0.19.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi->vllm==0.2.1.post1) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema->ray>=2.5.1->vllm==0.2.1.post1) (3.15.0)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=1292cf7b2faeeb17f4a19a36e7035e12515083935eecddf20dad41592ddd08cd\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/1b/ae/c752907c50ad9673ab23730ee731ce853f2cf69b2d98019dcd\n",
      "Successfully built lit\n",
      "Installing collected packages: sentencepiece, ninja, mpmath, lit, cmake, bitsandbytes, xxhash, uvloop, sympy, safetensors, regex, python-dotenv, pyarrow-hotfix, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, httptools, dill, absl-py, watchfiles, nvidia-cusolver-cu11, nvidia-cudnn-cu11, multiprocess, huggingface-hub, tokenizers, ray, transformers, datasets, triton, torch, xformers, accelerate, vllm, peft\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.4.0\n",
      "    Uninstalling absl-py-1.4.0:\n",
      "      Successfully uninstalled absl-py-1.4.0\n",
      "Successfully installed absl-py-1.3.0 accelerate-0.25.0 bitsandbytes-0.41.3 cmake-3.27.9 datasets-2.14.7 dill-0.3.7 httptools-0.6.1 huggingface-hub-0.17.3 lit-17.0.6 mpmath-1.3.0 multiprocess-0.70.15 ninja-1.11.1.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 peft-0.7.0 pyarrow-hotfix-0.6 python-dotenv-1.0.0 ray-2.8.1 regex-2023.10.3 safetensors-0.4.1 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.14.1 torch-2.0.1 transformers-4.34.0 triton-2.0.0 uvloop-0.19.0 vllm-0.2.1.post1 watchfiles-0.21.0 xformers-0.0.22 xxhash-3.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install peft transformers==4.34.0 tokenizers vllm==0.2.1.post1 bitsandbytes datasets absl-py==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d875a77-e12b-4fb7-bbef-e54e8b2113b8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29fb24a1-da33-43e2-9924-c9ccae223717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import sys\n",
    "from utils import Concatenator\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import os\n",
    "import json\n",
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "from snowflake.ml.model.models import llm\n",
    "\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "logger = logging.getLogger(\"snowflake.ml\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306b93f-c225-40ea-8480-10739c887b4d",
   "metadata": {},
   "source": [
    "### Load Base Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a599bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set your Hugging Face token\n",
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21622331-74b3-48b7-9b8f-5f1b7fba3e74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b203014f46a14112938ccebce1884c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7023bd99db4101a0717aa838b37af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186d4a03993a4ca2a7ee081aadbbf44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9023f1257064332bfa9c117e4cf86f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c299757d9acc4626979847c62ddac6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1d7602b4cc4725aeb3dc73bbcc82fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79278775d5ae430d9276d3133f689808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef57ecceab574a48826560a5738673cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6698fc861a0346deb6e40bb345260ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97001641f88648dd8dd16c761539d13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6238ca13a77d48e28360b204105a1a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "print('loading tokenizer')\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "print('loading model')\n",
    "model =LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a142a-182d-4a10-a92d-85410828226a",
   "metadata": {},
   "source": [
    "## Prepare Datasets\n",
    "### Load Datasets\n",
    "\n",
    "*IMP NOTE: Please do NOT not run the following cell during the bootcamp session. Fine-tuning on the entire dataset could take over an hour.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c2df6-84e2-4f5d-a019-4a31625e65bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def prepare_stratified_dataset(path, seed = 42):\n",
    "#     raw_df = pd.read_json(path, lines=True)\n",
    "#     raw_df['id'] = raw_df.index\n",
    "#     ds = Dataset.from_pandas(raw_df, split='train')\n",
    "#     cl = ClassLabel(num_classes=4, names=[\"EN\", \"FR\", \"DE\", \"ES\"])\n",
    "#     new_features = ds.features.copy()\n",
    "#     new_features['lang_label'] = cl\n",
    "#     cl_d = {l : cl.str2int(l) for l in [\"EN\", \"FR\", \"DE\", \"ES\"]}\n",
    "#     def convert_lang(sample):\n",
    "#         sample['lang_label'] = cl_d[sample['language']]\n",
    "#         return sample\n",
    "#     ds = ds.map(convert_lang, features=new_features)\n",
    "#     ds_split = ds.train_test_split(test_size=0.15, stratify_by_column='lang_label', seed=42)\n",
    "#     test_ds_split = ds_split['test'].train_test_split(test_size=2/3, stratify_by_column='lang_label', seed=42)\n",
    "#     return ds_split['train'].to_pandas(), test_ds_split['train'].to_pandas(), test_ds_split['test'].to_pandas()\n",
    "\n",
    "# train_df, eval_df, test_df = prepare_stratified_dataset(\n",
    "#     'transcripts.json'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ce0d6a-52f8-4a98-bb64-dffd9de39f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 1368\n",
      "Train        : 100\n",
      "Eval         : 100\n",
      "Test         : 100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"transcripts.json\", lines=True)\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "train_df = df.head(100)\n",
    "print(f\"Train        : {train_df.shape[0]}\")\n",
    "eval_df = df[200:300]\n",
    "print(f\"Eval         : {eval_df.shape[0]}\")\n",
    "test_df = df.tail(100)\n",
    "print(f\"Test         : {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48eb4986-85f7-4465-b56c-ef35f7edfa95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Barbie Science Lab Playset\"], \"location\": \"Sydney\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Barbie Dreamhouse 2023\"], \"location\": \"Los Angeles\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"], \"location\": \"Auckland\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Orijin Bees Lovey Coiley Baby Bee\"], \"location\": \"Vancouver\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Brisbane\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          instruction  \\\n",
       "0  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "1  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "2  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "3  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "4  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  input  \\\n",
       "0  \"caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!\"   \n",
       "1                                                                                                                                                 \"caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!\"   \n",
       "2                                                                                                                                                                                                                                                                                                                               \"caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!\"   \n",
       "3                                                                                                                                                                                                                                                                                                                                      \"caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!\"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    \"caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!\"   \n",
       "\n",
       "                                                                                                          output  \\\n",
       "0                                             {\"toy_list\": [\"Barbie Science Lab Playset\"], \"location\": \"Sydney\"}   \n",
       "1                                            {\"toy_list\": [\"Barbie Dreamhouse 2023\"], \"location\": \"Los Angeles\"}   \n",
       "2  {\"toy_list\": [\"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"], \"location\": \"Auckland\"}   \n",
       "3                                   {\"toy_list\": [\"Orijin Bees Lovey Coiley Baby Bee\"], \"location\": \"Vancouver\"}   \n",
       "4                                         {\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Brisbane\"}   \n",
       "\n",
       "  language  \n",
       "0       EN  \n",
       "1       EN  \n",
       "2       EN  \n",
       "3       EN  \n",
       "4       EN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79793829-d70f-4bed-93b2-1a4db2fbfaea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': Dataset.from_pandas(train_df),\n",
    "    'eval': Dataset.from_pandas(eval_df),\n",
    "    'test': Dataset.from_pandas(test_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb080d-a35e-4629-88d9-46c1d97c90dd",
   "metadata": {},
   "source": [
    "### Apply Prompt to Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e684e33f-d7db-4418-bab5-c3d490067fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "<</SYS>>\n",
    "### Instruction:\n",
    "{{instruction}}\n",
    "### Input:\n",
    "{{input_}}\n",
    "### Output:\n",
    "{{output}}\n",
    "{{eos_token}}\n",
    "\"\"\"\n",
    "\n",
    "eval_prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "<</SYS>>\n",
    "### Instruction:\n",
    "{{instruction}}\n",
    "### Input:\n",
    "{{input_}}\n",
    "### Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ff73e9-780a-44cd-b792-e351a9601f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ba2f444b3c474f939378d90cae47eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe64c5fed4944f99a7c0e68a4510b6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b88d7e3feba4b139fb8f61529249c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_train_template(sample):\n",
    "    return {\n",
    "        \"text\": train_prompt.format(\n",
    "            instruction=sample[\"instruction\"],\n",
    "            input_=sample[\"input\"].replace('\\\\n', '\\n'),\n",
    "            output=sample[\"output\"],\n",
    "            eos_token=tokenizer.eos_token,\n",
    "        )\n",
    "    }\n",
    "\n",
    "def apply_eval_template(sample):\n",
    "    return {\n",
    "        \"text\": eval_prompt.format(\n",
    "            instruction=sample[\"instruction\"],\n",
    "            input_=sample[\"input\"].replace('\\\\n', '\\n')\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "#applying template\n",
    "\n",
    "datasets['train'] = datasets['train'].map(apply_train_template, remove_columns=list(datasets['train'].features))\n",
    "for k in ['eval', 'test']:\n",
    "    datasets[k] = datasets[k].map(apply_eval_template, remove_columns=list(datasets[k].features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac551d54-0591-43bc-a96a-da5edd3aa565",
   "metadata": {},
   "source": [
    "### Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2290f191-ba23-4b83-8653-3d9c97d512cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89177194ba3424da0b1b75e3eea2f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490ff08131c747c6993c4620fa522924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab63fd7d08a4f1380bd4f5b5f7cfebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bfa34100d443d7981c896be8b94c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d83fd1ccf4a9392ceac19254a1d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c59bdf0e3c4660bf9cf8d4c2e03c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in datasets.items():\n",
    "    datasets[k] = v.map(\n",
    "        lambda sample: tokenizer(sample[\"text\"]),\n",
    "        batched=True,\n",
    "        remove_columns=list(v.features),\n",
    "    ).map(Concatenator(), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88447074-21a8-433a-a937-a3e3514650c4",
   "metadata": {},
   "source": [
    "## Fine-tune Llama 2 Model\n",
    "\n",
    "\n",
    "Fine-tuning is one form of model training. We start training from a pre-trained model and adjust a set of model parameters to better solve for a concrete task based on task specific data. Today we are going to fine-tune 7B Llama 2 model using LoRA (Low-Rank Adaptation)--which is a parameter efficient way of fine-tuning LLM. \n",
    "\n",
    "Instead of adjusting all the ~7B parameters, LoRA allows us to adjust only a percent of model weights--which can save compute and memory resources dramatically. For this lab, we will fine-tune our model using LoRA on a single A10 GPU. This will demostrate how good the inference can be on fine-tuned models even with limited compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ba1f466-d668-4f68-9d8d-ea7367b0369d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "#setting the model into training mode\n",
    "model.train()\n",
    "\n",
    "#setting up training\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_kbit_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b15d38d4-c399-4daa-9771-df29edf8c3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rm -r output_weights_dir # deletes prior fine tuning weights\n",
    "!mkdir output_weights_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649d974-40bb-4679-b5e7-e9da3f9cc75e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Configuration\n",
    "\n",
    "To achieve good performance for the task, you will need at least 1 `num_epochs`, feel free to explore this on your own and we've set `output_weights_dir` as the directory where the fine-tuned weights will be stored after fine-tuning job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "328c128c-5321-4132-a9b6-da362f62790c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"output_weights_dir\"\n",
    "enable_profiler = False\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 1,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674205dc-ded7-45eb-9450-a767ae5cfe85",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "#### Configuration\n",
    "\n",
    "We're passing `train_dataset` and `eval_dataset` that are used to generate loss calculation during fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4188f41a-0513-4848-aab6-fb0226d557f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.181, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 01:23, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profiler = nullcontext() \n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets['train'],\n",
    "        eval_dataset=datasets['eval'],\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "    \n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0f65d-5941-4b65-81e8-67dccf4c703b",
   "metadata": {},
   "source": [
    "## Log and Deploy Fine-tuned Llama 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57af43-9b3c-45ad-9ce3-eefdf5b79d99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Establish Secure Connection\n",
    "\n",
    "*NOTE: Update [connection.json](../connection.json) and set your password, Hugging Face token, and replace '####' with your user number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318991b7-c8f8-4c64-ba7f-d26be720e087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : USER0007\n",
      "Role                        : \"ROLE_USER0007\"\n",
      "Database                    : \"DB_USER0007\"\n",
      "Schema                      : \"SCHEMA_LLM\"\n",
      "Warehouse                   : \"WH_XS_USER0007\"\n",
      "Snowflake version           : 7.43.0\n",
      "Snowpark for Python version : 1.9.0\n"
     ]
    }
   ],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cc712-2d3d-41c5-b417-d18d0f2712e1",
   "metadata": {},
   "source": [
    "### Model Registery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d42c0c2-39d7-4024-b4ce-a23558ef124e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_model_registry() is in private preview since 0.2.0. Do not use it in production. \n",
      "WARNING:absl:The database DB_USER0007 already exists. Skipping creation.\n",
      "WARNING:absl:The schema DB_USER0007.SCHEMA_LLM already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"LLAMA2_7b_CHAT\"\n",
    "MODEL_VERSION = \"FineTunedV1.1\"\n",
    "DEPLOYMENT_NAME = \"FINETUNED_LLAMA2\"\n",
    "MODEL_REGISTRY_DB = connection_parameters['database']\n",
    "MODEL_REGISTRY_SCHEMA = connection_parameters['schema']\n",
    "COMPUTE_POOL = connection_parameters['compute_pool']\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=MODEL_REGISTRY_DB, \n",
    "    schema_name=MODEL_REGISTRY_SCHEMA, \n",
    "    create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3b75911-a7b7-4226-8b71-23a4a6dd9eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelRegistry.list_deployments() is in private preview since 1.0.1. Do not use it in production. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>MODEL_VERSION</th>\n",
       "      <th>DEPLOYMENT_NAME</th>\n",
       "      <th>CREATION_TIME</th>\n",
       "      <th>TARGET_METHOD</th>\n",
       "      <th>TARGET_PLATFORM</th>\n",
       "      <th>SIGNATURE</th>\n",
       "      <th>OPTIONS</th>\n",
       "      <th>STAGE_PATH</th>\n",
       "      <th>ROLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MODEL_NAME, MODEL_VERSION, DEPLOYMENT_NAME, CREATION_TIME, TARGET_METHOD, TARGET_PLATFORM, SIGNATURE, OPTIONS, STAGE_PATH, ROLE]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.list_deployments(model_name=MODEL_NAME,model_version=MODEL_VERSION).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26134b3-9f3b-4834-91e6-d3115a605502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# registry.delete_deployment(model_name=MODEL_NAME,model_version=MODEL_VERSION,deployment_name=DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2f21a-cfcb-459b-afe8-c859acad9a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# registry.delete_model(model_name=MODEL_NAME,model_version=MODEL_VERSION,delete_artifact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ef244-2df3-46e5-ac6d-b4c40bb56fc5",
   "metadata": {},
   "source": [
    "### Reference Llama 2 from Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ff039a5-36b9-4642-a242-b67e75a66e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelRegistry.log_model() is in private preview since 0.2.0. Do not use it in production. \n",
      "WARNING:snowflake.snowpark:ModelRegistry.list_models() is in private preview since 0.2.0. Do not use it in production. \n",
      "WARNING:snowflake.snowpark:ModelRegistry.deploy() is in private preview since 0.2.0. Do not use it in production. \n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/snowflake/ml/model/_packager/model_env/model_env.py:353: UserWarning: Found dependencies specified as pip requirements. This may prevent model deploying to Snowflake Warehouse.\n",
      "  warnings.warn(\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.17 s, sys: 0 ns, total: 4.17 s\n",
      "Wall time: 30min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'DB_USER0007.SCHEMA_LLM.FINETUNED_LLAMA2',\n",
       " 'platform': <TargetPlatform.SNOWPARK_CONTAINER_SERVICES: 'SNOWPARK_CONTAINER_SERVICES'>,\n",
       " 'target_method': 'infer',\n",
       " 'signature': ModelSignature(\n",
       "                     inputs=[\n",
       "                         FeatureSpec(dtype=DataType.STRING, name='input')\n",
       "                     ],\n",
       "                     outputs=[\n",
       "                         FeatureSpec(dtype=DataType.STRING, name='generated_text')\n",
       "                     ]\n",
       "                 ),\n",
       " 'options': {'compute_pool': 'COMPUTE_POOL_USER0007', 'num_gpus': 1},\n",
       " 'details': {'image_name': 'sfsenorthamerica-build-spcs3.registry.snowflakecomputing.com/db_user0007/schema_llm/snowml_repo/a2dc5950178b8bf1c3764f03dddcbe86ea99c226:latest',\n",
       "  'service_spec': \"spec:\\n  container:\\n  - env:\\n      MODEL_ZIP_STAGE_PATH: /DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_A46C4E38948E11EEA917C651EA7AA6AC/model.zip\\n      NUM_WORKERS: 1\\n      SNOWML_USE_GPU: true\\n      TARGET_METHOD: infer\\n      _CONCURRENT_REQUESTS_MAX: 1\\n    image: sfsenorthamerica-build-spcs3.registry.snowflakecomputing.com/db_user0007/schema_llm/snowml_repo/a2dc5950178b8bf1c3764f03dddcbe86ea99c226:latest\\n    name: inference-server\\n    readinessProbe:\\n      path: /health\\n      port: 5000\\n    resources:\\n      limits:\\n        nvidia.com/gpu: 1\\n      requests:\\n        nvidia.com/gpu: 1\\n    volumeMounts:\\n    - mountPath: /local/user/vol1\\n      name: vol1\\n    - mountPath: DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_A46C4E38948E11EEA917C651EA7AA6AC\\n      name: stage\\n  endpoint:\\n  - name: predict\\n    port: 5000\\n  volume:\\n  - name: vol1\\n    source: local\\n  - gid: 1000\\n    name: stage\\n    source: '@DB_USER0007.SCHEMA_LLM.SNOWML_MODEL_A46C4E38948E11EEA917C651EA7AA6AC'\\n    uid: 1000\\n\",\n",
       "  'service_function_sql': \"\\n            CREATE OR REPLACE FUNCTION DB_USER0007.SCHEMA_LLM.FINETUNED_LLAMA2(input OBJECT)\\n                RETURNS OBJECT\\n                SERVICE=DB_USER0007.SCHEMA_LLM.service_a46c4e38948e11eea917c651ea7aa6ac\\n                ENDPOINT=predict\\n                MAX_BATCH_ROWS = 100\\n                AS '/predict'\\n            \"}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#referencing our fine tuned model\n",
    "#referencing huggingface token\n",
    "options = llm.LLMOptions(\n",
    "    token=connection_parameters['huggingface_token'],\n",
    "    max_batch_size=100,\n",
    ")\n",
    "#referencing our fine tuned weights and using the hugging face token to merge with base llama model\n",
    "llama_model = llm.LLM(\n",
    "    model_id_or_path='output_weights_dir',\n",
    "    options=options\n",
    ")\n",
    "\n",
    "# log model in registry\n",
    "llama_model_ref = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model\n",
    ")\n",
    "\n",
    "# deploy model\n",
    "llama_model_ref.deploy(\n",
    "    deployment_name=DEPLOYMENT_NAME, \n",
    "    platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    permanent=True, \n",
    "   options={\"compute_pool\": COMPUTE_POOL, \"num_gpus\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae82d020-a7ce-4a88-858f-5467b88406db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if its already deployed run the following:\n",
    "llama_model_ref = model_registry.ModelReference(\n",
    "    registry=registry, \n",
    "    model_name=MODEL_NAME, \n",
    "    model_version=MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654a572-97fb-48bb-a1b3-510a5d62690e",
   "metadata": {},
   "source": [
    "## Inference on Eval Dataset using fine-tuned Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd360c91-5df0-44ac-bbb6-b07f13bac9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69/3143168716.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_df['input'] = eval_df.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Jack, and I'm looking for a toy for my niece.\\nfrosty: Hello Jack! I'm Frosty, and I'd be happy to help you find the perfect toy. Where are you calling from?\\ncaller: I'm calling from Cape Town, South Africa.\\nfrosty: Thank you, Jack from Cape Town! Can you tell me a bit about your niece's interests so we can find a great toy for her?\\ncaller: She's really into animals and likes playing pretend with her toys.\\nfrosty: How about the Fisher-Price Little People Mickey and Friends Playset? This playset features animal characters and is perfect for encouraging imaginative play.\\ncaller: That sounds nice, but I think she'd prefer something focused on real animals.\\nfrosty: In that case, the Calico Critters Pony's Stylish Hair Salon may be just the toy you're looking for. It comes with pony figurines and a cute hair salon for them.\\ncaller: Oh, that sounds perfect! Let's go with the pony's hair salon.\\nfrosty: Great choice! We've added the Calico Critters Pony's Stylish Hair Salon to your holiday wish list. Before we finish though, can you tell me how you plan to celebrate the holiday season?\\ncaller: Sure, I'll be spending the holidays at the beach with my family and enjoying the warm weather.\\nfrosty: That sounds amazing! To confirm, your toy list includes the Calico Critters Pony's Stylish Hair Salon. Is that correct?\\ncaller: Yes, that's correct. Thank you!+\\nfrosty: You're welcome, Jack! It's been a pleasure assisting you. Have a fantastic holiday season!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi Frosty, I'm Emily.\\nfrosty: Hello Emily! I'm here to help you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Sydney, Australia.\\nfrosty: Thank you, Emily from Sydney! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for a toy that's educational and fun for my son. He's really into science and technology.\\nfrosty: How about the Thames &amp; Kosmos Candy Vending Machine STEM experiment kit? It combines science and technology with creating a candy vending machine!\\ncaller: That sounds great, but I'd like to explore some more options before deciding.\\nfrosty: Sure thing! We also have the LeapFrog Magic Adventures Microscope, which allows kids to explore the world of science up-close with a real working microscope.\\ncaller: I think the magic microscope is the one! Let's add that to my wish list.\\nfrosty: Fantastic choice! I've added the LeapFrog Magic Adventures Microscope to your list. Before we wrap up, tell me a bit about your favorite way to spend time during the holiday season.\\ncaller: I enjoy baking holiday treats and watching seasonal movies with my family.\\nfrosty: That sounds delightful! To confirm, your toy list includes the LeapFrog Magic Adventures Microscope. Is everything correct?\\ncaller: Yes, it is. Thanks for your help, Frosty!\\nfrosty: You're welcome, Emily! Have a wonderful holiday season!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi, I'm David!\\nfrosty: Hello David! I'm Frosty, and I'm here to help you submit your holiday wish list. Can you tell me where you're calling from?\\ncaller: I'm calling from Auckland, New Zealand.\\nfrosty: Thank you, David from Auckland. What item would you like to add to your holiday wish list?\\ncaller: I want to get a fun toy for my daughter, but I'm not sure what to choose.\\nfrosty: No worries, let's explore a few options together. What are some of your daughter's interests?\\ncaller: She loves playing with dolls and watching animated shows.\\nfrosty: How about the Gabbys Dollhouse Cruise Ship? It's based on the popular animated show and offers imaginative play with a fun cruise ship and doll figurines.\\ncaller: That sounds good, but I'd like to see more options, please.\\nfrosty: Of course! You might also consider the Bluey Ultimate Lights and Sounds Playhouse, based on the popular animated show Bluey. It has interactive lights and sounds that bring the playhouse to life.\\ncaller: Those both sound good, but I think my daughter would prefer the gabby dollhouse.\\nfrosty: Great choice! I've added the Gabbys Dollhouse Cruise Ship to your holiday wish list. Now, tell me about your favorite holiday memory.\\ncaller: My favorite memory is when we all went ice skating together as a family during the holidays.\\nfrosty: Sounds like a wonderful experience! To confirm, your toy list includes the Gabbys Dollhouse Cruise Ship. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Excellent! Your wish list is all set. Have a fantastic holiday season, David!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hello, my name is Sarah.\\nfrosty: Hi Sarah! I'm Frosty, a voice bot here to assist you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Los Angeles, United States.\\nfrosty: Thank you, Sarah from Los Angeles! Let's get started on your wish list. What's the first item you have in mind?\\ncaller: I'm thinking of getting the pokemon plushie for my son, but I'm not sure.\\nfrosty: The Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack is an excellent choice for Pok\\u00e9mon fans! What do you think your son will enjoy the most about this toy?\\ncaller: He loves collecting Pok\\u00e9mon toys and watching the animated series, so I think he'd enjoy adding this to his collection.\\nfrosty: That's a great reason to choose this toy! How do you and your family plan to celebrate the holiday season?\\ncaller: We'll be hosting a game night and enjoying holiday treats with our loved ones.\\nfrosty: That sounds like a great way to spend the holidays! To confirm, your toy list includes the Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Wonderful! Your toys have been added to your holiday wish list. Happy holidays, Sarah!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Liam.\\nfrosty: Hello Liam! I'm Frosty, and I'm here to help you submit your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Dublin, Ireland.\\nfrosty: Thank you, Liam from Dublin! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for something for my younger sister, but I'm not quite sure what she'd like.\\nfrosty: I'm here to help! Can you tell me a bit about your sister's interests and hobbies?\\ncaller: She loves arts and crafts, and she also enjoys watching nature documentaries.\\nfrosty: How about the National Geographic Mega Slime Kit &amp; Putty Lab? It combines her love for crafts and nature with fun, slime-filled experiments.\\ncaller: That sounds interesting, but let's explore some more options.\\nfrosty: We also have the Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set, which allows her to create and learn using eco-friendly foam.\\ncaller: I believe the playfoam letters would be a perfect match! Let's add that to the list.\\nfrosty: Wonderful! We've added the Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set to your holiday wish list. Before we finish, can you tell me one of your favorite holiday memories?\\ncaller: My favorite holiday memory was when my family and I went to visit the local Christmas markets and enjoyed a cozy evening together.\\nfrosty: Sounds lovely! To confirm, your toy list includes the Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set. Is that correct?\\ncaller: Yes, that's correct!\\nfrosty: Fantastic! Your toy list is complete. Have a happy holiday season, Liam!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers\"], \"location\": \"Dublin\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          instruction  \\\n",
       "0  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "1  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "2  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "3  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "4  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   input  \\\n",
       "0                                                                                                   \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Jack, and I'm looking for a toy for my niece.\\nfrosty: Hello Jack! I'm Frosty, and I'd be happy to help you find the perfect toy. Where are you calling from?\\ncaller: I'm calling from Cape Town, South Africa.\\nfrosty: Thank you, Jack from Cape Town! Can you tell me a bit about your niece's interests so we can find a great toy for her?\\ncaller: She's really into animals and likes playing pretend with her toys.\\nfrosty: How about the Fisher-Price Little People Mickey and Friends Playset? This playset features animal characters and is perfect for encouraging imaginative play.\\ncaller: That sounds nice, but I think she'd prefer something focused on real animals.\\nfrosty: In that case, the Calico Critters Pony's Stylish Hair Salon may be just the toy you're looking for. It comes with pony figurines and a cute hair salon for them.\\ncaller: Oh, that sounds perfect! Let's go with the pony's hair salon.\\nfrosty: Great choice! We've added the Calico Critters Pony's Stylish Hair Salon to your holiday wish list. Before we finish though, can you tell me how you plan to celebrate the holiday season?\\ncaller: Sure, I'll be spending the holidays at the beach with my family and enjoying the warm weather.\\nfrosty: That sounds amazing! To confirm, your toy list includes the Calico Critters Pony's Stylish Hair Salon. Is that correct?\\ncaller: Yes, that's correct. Thank you!+\\nfrosty: You're welcome, Jack! It's been a pleasure assisting you. Have a fantastic holiday season!\"\\n### Output:\\n   \n",
       "1                                                                                                                                                                                                  \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi Frosty, I'm Emily.\\nfrosty: Hello Emily! I'm here to help you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Sydney, Australia.\\nfrosty: Thank you, Emily from Sydney! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for a toy that's educational and fun for my son. He's really into science and technology.\\nfrosty: How about the Thames & Kosmos Candy Vending Machine STEM experiment kit? It combines science and technology with creating a candy vending machine!\\ncaller: That sounds great, but I'd like to explore some more options before deciding.\\nfrosty: Sure thing! We also have the LeapFrog Magic Adventures Microscope, which allows kids to explore the world of science up-close with a real working microscope.\\ncaller: I think the magic microscope is the one! Let's add that to my wish list.\\nfrosty: Fantastic choice! I've added the LeapFrog Magic Adventures Microscope to your list. Before we wrap up, tell me a bit about your favorite way to spend time during the holiday season.\\ncaller: I enjoy baking holiday treats and watching seasonal movies with my family.\\nfrosty: That sounds delightful! To confirm, your toy list includes the LeapFrog Magic Adventures Microscope. Is everything correct?\\ncaller: Yes, it is. Thanks for your help, Frosty!\\nfrosty: You're welcome, Emily! Have a wonderful holiday season!\"\\n### Output:\\n   \n",
       "2               \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi, I'm David!\\nfrosty: Hello David! I'm Frosty, and I'm here to help you submit your holiday wish list. Can you tell me where you're calling from?\\ncaller: I'm calling from Auckland, New Zealand.\\nfrosty: Thank you, David from Auckland. What item would you like to add to your holiday wish list?\\ncaller: I want to get a fun toy for my daughter, but I'm not sure what to choose.\\nfrosty: No worries, let's explore a few options together. What are some of your daughter's interests?\\ncaller: She loves playing with dolls and watching animated shows.\\nfrosty: How about the Gabbys Dollhouse Cruise Ship? It's based on the popular animated show and offers imaginative play with a fun cruise ship and doll figurines.\\ncaller: That sounds good, but I'd like to see more options, please.\\nfrosty: Of course! You might also consider the Bluey Ultimate Lights and Sounds Playhouse, based on the popular animated show Bluey. It has interactive lights and sounds that bring the playhouse to life.\\ncaller: Those both sound good, but I think my daughter would prefer the gabby dollhouse.\\nfrosty: Great choice! I've added the Gabbys Dollhouse Cruise Ship to your holiday wish list. Now, tell me about your favorite holiday memory.\\ncaller: My favorite memory is when we all went ice skating together as a family during the holidays.\\nfrosty: Sounds like a wonderful experience! To confirm, your toy list includes the Gabbys Dollhouse Cruise Ship. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Excellent! Your wish list is all set. Have a fantastic holiday season, David!\"\\n### Output:\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                          \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hello, my name is Sarah.\\nfrosty: Hi Sarah! I'm Frosty, a voice bot here to assist you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Los Angeles, United States.\\nfrosty: Thank you, Sarah from Los Angeles! Let's get started on your wish list. What's the first item you have in mind?\\ncaller: I'm thinking of getting the pokemon plushie for my son, but I'm not sure.\\nfrosty: The Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack is an excellent choice for Pok\\u00e9mon fans! What do you think your son will enjoy the most about this toy?\\ncaller: He loves collecting Pok\\u00e9mon toys and watching the animated series, so I think he'd enjoy adding this to his collection.\\nfrosty: That's a great reason to choose this toy! How do you and your family plan to celebrate the holiday season?\\ncaller: We'll be hosting a game night and enjoying holiday treats with our loved ones.\\nfrosty: That sounds like a great way to spend the holidays! To confirm, your toy list includes the Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Wonderful! Your toys have been added to your holiday wish list. Happy holidays, Sarah!\"\\n### Output:\\n   \n",
       "4  \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Liam.\\nfrosty: Hello Liam! I'm Frosty, and I'm here to help you submit your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Dublin, Ireland.\\nfrosty: Thank you, Liam from Dublin! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for something for my younger sister, but I'm not quite sure what she'd like.\\nfrosty: I'm here to help! Can you tell me a bit about your sister's interests and hobbies?\\ncaller: She loves arts and crafts, and she also enjoys watching nature documentaries.\\nfrosty: How about the National Geographic Mega Slime Kit & Putty Lab? It combines her love for crafts and nature with fun, slime-filled experiments.\\ncaller: That sounds interesting, but let's explore some more options.\\nfrosty: We also have the Playfoam Naturals Shape & Learn Letters & Numbers set, which allows her to create and learn using eco-friendly foam.\\ncaller: I believe the playfoam letters would be a perfect match! Let's add that to the list.\\nfrosty: Wonderful! We've added the Playfoam Naturals Shape & Learn Letters & Numbers set to your holiday wish list. Before we finish, can you tell me one of your favorite holiday memories?\\ncaller: My favorite holiday memory was when my family and I went to visit the local Christmas markets and enjoyed a cozy evening together.\\nfrosty: Sounds lovely! To confirm, your toy list includes the Playfoam Naturals Shape & Learn Letters & Numbers set. Is that correct?\\ncaller: Yes, that's correct!\\nfrosty: Fantastic! Your toy list is complete. Have a happy holiday season, Liam!\"\\n### Output:\\n   \n",
       "\n",
       "                                                                                            output  \\\n",
       "0             {\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}   \n",
       "1                     {\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}   \n",
       "2                           {\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}   \n",
       "3  {\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}   \n",
       "4        {\"toy_list\": [\"Playfoam Naturals Shape & Learn Letters & Numbers\"], \"location\": \"Dublin\"}   \n",
       "\n",
       "  language  \n",
       "0       EN  \n",
       "1       EN  \n",
       "2       EN  \n",
       "3       EN  \n",
       "4       EN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['input'] = eval_df.apply(\n",
    "    lambda x: eval_prompt.format(\n",
    "        instruction=x[\"instruction\"],\n",
    "        input_=x[\"input\"].replace('\\\\n', '\\n')\n",
    "    ), axis=1\n",
    ")\n",
    "eval_df.reset_index(drop=True, inplace=True)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd02bca2-f2be-4d2e-b41c-9d0c6775cb35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelReference.predict() is in private preview since 0.2.0. Do not use it in production. \n",
      "WARNING:snowflake.snowpark:ModelRegistry.get_deployment() is in private preview since 1.0.1. Do not use it in production. \n",
      "/tmp/ipykernel_69/3612286001.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_df['predicted'] = llama_model_ref.predict(deployment_name=DEPLOYMENT_NAME,data=eval_df)#.head()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}</td>\n",
       "      <td>\"location\": \"Cape Town\",\\n\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value of 'location' is 'Cape Town', which is the city provided by the caller. The value of 'toy_list' is a list containing only one toy,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}</td>\n",
       "      <td>\"location\": \"Sydney, Australia\",\\n\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value for 'location' is \"Sydney, Australia\", which is the city provided by the caller. The value for 'toy_list' is an array containing the single item \"Leap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}</td>\n",
       "      <td>\"location\": \"Auckland, New Zealand\",\\n\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with 'location' and 'toy_list' as keys.\\n\\n### Hint: You can use the 'location' key to extract the location of the caller, which is Auckland, New Zealand in this case. Similarly, you can use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}</td>\n",
       "      <td>\"{\\n'location': 'Los Angeles',\\n'toy_list': ['Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack']\\n}\"\\n\\nPlease provide the JSON response with the extracted information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"toy_list\": [\"Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers\"], \"location\": \"Dublin\"}</td>\n",
       "      <td>\"location\": \"Dublin, Ireland\",\\n\"toy_list\": [\"Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with the 'location' and 'toy_list' keys.\\n\\n### Expected Output:\\n{\"location\": \"Dublin, Ireland\", \"toy_list\": [\"Playfoam Naturals Shape &amp; Lear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            output  \\\n",
       "0             {\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}   \n",
       "1                     {\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}   \n",
       "2                           {\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}   \n",
       "3  {\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}   \n",
       "4        {\"toy_list\": [\"Playfoam Naturals Shape & Learn Letters & Numbers\"], \"location\": \"Dublin\"}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                               predicted  \n",
       "0                         \"location\": \"Cape Town\",\\n\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value of 'location' is 'Cape Town', which is the city provided by the caller. The value of 'toy_list' is a list containing only one toy,  \n",
       "1  \"location\": \"Sydney, Australia\",\\n\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value for 'location' is \"Sydney, Australia\", which is the city provided by the caller. The value for 'toy_list' is an array containing the single item \"Leap  \n",
       "2                    \"location\": \"Auckland, New Zealand\",\\n\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with 'location' and 'toy_list' as keys.\\n\\n### Hint: You can use the 'location' key to extract the location of the caller, which is Auckland, New Zealand in this case. Similarly, you can use  \n",
       "3                                                                                                                                                                                             \"{\\n'location': 'Los Angeles',\\n'toy_list': ['Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack']\\n}\"\\n\\nPlease provide the JSON response with the extracted information.  \n",
       "4                                                 \"location\": \"Dublin, Ireland\",\\n\"toy_list\": [\"Playfoam Naturals Shape & Learn Letters & Numbers set\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with the 'location' and 'toy_list' keys.\\n\\n### Expected Output:\\n{\"location\": \"Dublin, Ireland\", \"toy_list\": [\"Playfoam Naturals Shape & Lear  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['predicted'] = llama_model_ref.predict(deployment_name=DEPLOYMENT_NAME,data=eval_df)#.head()\n",
    "eval_df[['output', 'predicted']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac4d8d-72c0-40ab-ae3d-54ac20f6874e",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "Delete deployment and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a53426a-93a8-4bb2-88d1-da6a885b9fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelRegistry.delete_deployment() is in private preview since 1.0.1. Do not use it in production. \n",
      "WARNING:snowflake.snowpark:ModelRegistry.delete_model() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "llama_model_ref.delete_deployment(deployment_name=DEPLOYMENT_NAME)\n",
    "llama_model_ref.delete_model(delete_artifact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba271759-a482-4d8f-898c-a0170a33c709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
